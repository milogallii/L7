\chapter{Related Works}\label{ch:related}

\section{OT Security overview}
In recent years, there has been a concerted effort to modernize and fortify critical maritime OT infrastructures. This initiative has given rise to the development of cybersecurity campaigns and directives, which have in turn identified opportunities to enhance the management of control systems and network operations. These are comprised of a set of rules and procedures that aim to raise awareness of potential cyber risks as well as to define the behaviors that are to be adopted, identifying the human factor as the most significant vulnerability, as stated in a serie of articles and online resources such as \cite{industry_approach}, \cite{securing_maritime}, \cite{maritime_decision_makers}, \cite{cyber_preparedness}.

Although solutions that do not necessitate additional software or hardware appear to be the prevailing preference with a notable emphasis on personnel training the necessity of a technical response to this threat has been underscored as well: \cite{integrated_ship_cybersecurity}.

The modern industry is shaped by innovative concepts and technologies that aimed towards interconnectedness facilitated by machine-to-machine and machine-to-control system communications. Keeping this in mind critical challenges in securing OT systems were born needing solutions that prioritized availability, integrity and confidenciality.

Moreover, the integration of information technology (IT) and operational technology (OT) infrastructures within contemporary architectural frameworks has unveiled a plethora of previously unacknowledged vulnerabilities and threats. This integration has led to an augmentation of complexity and interconnectedness, thereby expanding the attack surface significantly. In light of these developments, the necessity for novel risk assessment methodologies has become apparent to ensure the proper security of infrastructures.

Within the domain of OT systems, two primary methods have emerged: qualitative and quantitative. Qualitative assessment prioritizes individual risks based on the probability of their occurrence, whereas quantitative assessment analyzes risk numerically by assigning it a numerical value. 
Presently, the preponderance of maritime physical risk assessments is rooted in probability statistics.

The development of a qualitative risk assessment framework for cyber risks in maritime environments poses significant challenges. The scarcity of data, attributable to the limitations of reporting abilities and the novelty of this emerging risk, contributes to the volatility of maritime cyber data, making reliable probability estimation challenging. 

In addition to the aforementioned points, the measurement of cyber risk has been conducted on numerous occasions in a variety of sectors and their systems. However, there has been a paucity of such studies in the maritime sector, which has been estimated to be approximately two decades behind cyber-security trends. The unique systems, protocols, and the movement across physical and cyber spaces mean that traditional methods of risk assessment cannot be easily applied without modifications to existing infrastructures. The unique blend of these factors create a distinct maritime risk landscape that can result in outcomes such as loss of finance, loss of life, and environmental damage.

\section{Hardware Solutions}
In consideration of the interconnection among components, the principal vulnerability in this approach is identified in the communication channel. Consequently, it is hypothesized that an attacker can gain access to the network and identify vulnerabilities in the process controlled by a system component. 

The proposed solution to this problem is the implementation of intrusion detection systems of variable complexity, which necessitate the integration of additional hardware components within the existing infrastructure whose purpose would be to analyze network traffic seeking potential attack patterns. The work published in the article \cite{fog_ids} will be taken as example for the following considerations on the reasons that lead us to believe that this is a non optimal solution, following also the topics found in \cite{hardware_security}. The introduction of new hardware components invariably gives rise to a multitude of issues, largely due to their physical characteristics. 

\subsection{Hardware Security and Hardware Trust}

The emergence of hardware security concerns is attributable to its inherent vulnerability to attacks across various levels. Additionally, the absence of robust hardware support for software and system security contributes to these concerns. Conversely, issues pertaining to hardware trust arise from the involvement of untrusted entities in the life cycle of a hardware component, including entities such as untrusted IP or computer-aided design tool vendors, as well as untrusted design, fabrication, test, or distribution facilities. 

These entities have the potential to compromise the trustworthiness of a hardware component or system  and could potentially cause deviations from the intended functional behavior, performance, or reliability of the hardware. Trust issues can also lead to other incidents, such as poor parametric behavior, or degraded reliability, or safety issues.
\leavevmode\newline

\begin{tabularx}{\textwidth}{|>{\hsize=0.45\hsize}X|>{\hsize=1.55\hsize}X|}
  \hline
  \multicolumn{2}{|c|}{\textbf{Attack Vectors rising from each step of hardware manifacture}} \\ \hline
  Life Cycle Step & Attack Vector\\ \hline
    IP Vendor & H/W Trojan Insertion, Hidden backdoor placement \\ \hline
    SOC Design House & IP Piracy, Trojan in Design \\ \hline
    Foundry &  Implant Trojan, Overproduction Cloning\\ \hline
    Deployment & Side Channel Attacks, Reverse Engineering, Scan Based attacks, IC Counterfeiting \\ \hline
\end{tabularx}

\leavevmode\newline

\subsection{Attack surface exposure}
The term "attack surface" is used to denote the totality of all potential security risk exposures. This concept can be further elucidated by defining it as the aggregate of all known, unknown, and potential vulnerabilities, along with the corresponding controls, across all hardware, software, and network components. The objective of developing countermeasures is often to minimize the attack surface.
With respect to hardware security, three main attack surfaces are as follows

\begin{itemize}
    \item\textbf{Chip Level Attacks} : Chips are susceptible to targeted attacks, including reverse engineering, cloning, malicious insertion, side-channel attacks, and piracy. In the event that an attacker is able to create a copy that closely resembles the original, counterfeit or fake chips can be sold as authentic units. Additionally, the presence of Trojan-infected chips within the supply chain can pose a threat of unauthorized access or malfunction. Side-channel attacks, in particular, present a significant threat, as they can be used to extract secret information stored within the chip.
    \item\textbf{PCB Level Attacks} : Printed circuit boards (PCBs) are frequently targeted by attackers due to their relative ease of reverse engineering and tampering when compared to the complexity of entire system components. The design information of most modern PCBs can be extracted through relatively simple optical inspection and efficient signal processing. The primary objectives of these attacks are twofold: first, to reverse engineer the PCB, and second, to obtain the schematic of the board to redesign it and create fake units. Attackers may also physically tamper with a PCB to render it susceptible to leakage of sensitive information or to circumvent digital rights management (DRM) protections.
    \item\textbf{System-Level Attacks} : Complex attacks involving the interaction of hardware and software components can be mounted on the system. By directly targeting the most vulnerable components within a system, such as the Design-for-Test (DFT) infrastructure at PCB level and memory modules, attackers may be able to compromise the system's security, thereby gaining unauthorized control and access to sensitive data.
\end{itemize}

Furthermore, vulnerabilities related to weakness in hardware architecture, implementation, or design/test process must be taken into consideration.
These vulnerabilities can be classified as either functional or nonfunctional, and their manifestation is contingent on the system's nature and its intended usage scenarios. With respect to hardware, the most prevalent causes of vulnerabilities can be identified in the following bugs :

\begin{itemize}
    \item\textbf{Functional Bug} : The majority of vulnerabilities are attributable to functional bugs and substandard design and testing practices. These vulnerabilities encompass a range of issues, including the implementation of weak cryptographic hardware and the inadequate protection of assets within a system. Attackers may identify these vulnerabilities by meticulously analyzing the functionality of a system under various input conditions to identify any anomalous behavior.
    \item\textbf{Side-Channel Bug} : These bugs are indicative of implementation-level issues that result in the leakage of critical information stored within a hardware component via various forms of side-channels. Attackers may identify these vulnerabilities by analyzing the side-channel signals during the operation of a hardware component.
    \item\textbf{Test/Debug infrastructure}: The preponderance of hardware systems offers a satisfactory degree of testability and debuggability, thereby empowering designers and test engineers to validate the operational integrity of these systems. These systems also facilitate the study of internal operations and processes running on the hardware, which are essential for debugging the hardware. However, these infrastructures are not immune to exploitation by malicious actors. In the wrong hands, test/debug features can be used for extracting sensitive information or gaining unauthorized control of a system.
    \item\textbf{Access control or information-flow issues} :  In certain instances, a system may exhibit a lack of distinction between authorized and unauthorized users. This vulnerability can potentially enable an attacker to gain access to sensitive assets and functionalities that may be exploited for malicious purposes. Furthermore, an intelligent adversary can monitor the information flow during system operation to decipher security-critical information, such as the control flow of a program and the memory address of a protected region from a hardware perspective.
\end{itemize}

\subsection{Considerations}
The aforementioned discourse expounds on the predominant rationales elucidating why the incorporation of hardware components does not constitute a paradigm of ideal solutions to our implementation from an empirical standpoint. A comprehensive explanation can be found in a seminal article from the Journal of Computational and Cognitive Engineering, \cite{reliability_analisys}, which demonstrates that the optimal availability of a system can be achieved only if it is periodically completely repaired and supporting units have been invoked.

This finding holds particular relevance to the proposed solution by the Rome University, which if implemented would require, in a system with a greater number of components, a more complex and potentially more maintenance-intensive solution. In contrast, our implementation relies exclusively on a software-based solution, circumventing the previously identified defects. Furthermore, it can be seamlessly integrated into existing devices without requiring any hardware modifications, a key advantage over cited approaches.

\section{Protocol Solutions}
In light of the maritime communication systems current state, alternative solutions have been proposed in the domain of information exchange standards. These proposals have identified the underlying issues as stemming from the utilization of outdated systems that employ data exchange methodologies devoid of any data analysis nor cyber/security considerations. There is a growing recognition of the need for a novel smart communication system, as evidenced by numerous sources that have proposed designs emphasizing network architecture, air interface, and radio spectrum, with the objective of enabling e-Navigation. This encompasses a range of autonomous and semi-autonomous navigation systems that utilize 5G, LTE, satellite, and radio communications, superseding the prevailing standards outlined in the literature, as cited in \cite{maritime_iot} \cite{vhf_data_exchange}.

\subsection{Industry Concerns}
The majority of vessels and naval infrastructures currently sailing around the globe are old transports with legacy devices providing connectivity and managing internal state and network capabilities. This circumstance can be identified with ease as the primary impediment to the realization of e-Navigation, which can be formalized as a series of challenges that must be confronted. These challenges include, but are not limited to:

\begin{itemize}
    \item\textbf{Ubiquitous Connectivity and Service Continuity} : The creation of a new maritime system is predicated on the imperative to ensure ubiquitous connectivity between vessels and shore on a global scale, especially over open oceans.  Furthermore, the deployment of these services has historically been limited to a campus-style model, resulting in inconsistent and, at times, non-existent cross-region continuity of maritime service. Consequently a global network would be crucial for providing consistent and continuous maritime services worldwide, especially in remote and inaccessible regions such as the polar regions
    \item\textbf{Traffic Nonuniformity} : Notwithstanding its global reach, maritime traffic is characterized by significant disparities in distribution. Concentrated flows of maritime traffic are a common occurrence in ports, along coastal areas, and along waterways.
    For instance, coastal shipping accounts for more than 50 percent of the total ship transport to and from the ports of the coastal countries, where the cargo vessels primarily follow the routes that are set close to the shore wherever possible. In contrast, traffic on the high seas is primarily attributable to intercontinental transportation or deep sea shipping, and is comparatively sparse in density. The maritime traffic management network must therefore be equipped with an efficient solution to cope with this type of traffic pattern
    \item\textbf{Service Centricity} : In contrast to conventional mobile networks, which are designed around a specific network architecture, maritime MTC systems must facilitate the efficient provisioning, discovery, and execution of diverse maritime application and service components distributed across the network. This is essential for realizing the full potential of transitioning to maritime IoT.  Consequently, a new maritime system should not be confined to a one-time design and deployment; it is expected to offer amorphous services that adapt to a wide variety of maritime specific needs, and match changing demands. Hence, both network configuration and communication resources must be made flexible and adaptive to the specific service offered 
    \item\textbf{Device Heterogeneity} : To accommodate a wide array of maritime IoT applications, maritime systems must be capable of supporting a diverse range of devices, spanning from the lower-end category, which encompasses devices with constrained functionality to the higher-end category, which includes devices with comprehensive functionality. This extensive heterogeneity in communication capability, encompassing hardware, power supplies, interoperability, and protocols, necessitates the implementation of an efficient system capable of accommodating this variation under a unified framework.
    \item\textbf{Simplicity and Reliability} : In contrast to the majority of terrestrial systems, simplicity has historically served as the overarching criterion for the design of maritime communication systems. A simplified system is less expensive to manufacture and maintain, and it is generally more robust and reliable in complex marine environments. Indeed, reliability is of paramount importance to maritime systems, while cost is also a significant factor that cannot be disregarded. Consequently, the selection and development of technology must prioritize cost-effectiveness and the provision of complimentary loyalty services.
    \item\textbf{Capacity and Scalability} : Constrained by the paucity of communication resources, enhancing efficiency emerges as the pivotal strategy to optimize the system's capacity. It is imperative to optimize physical and higher layers to facilitate more spectrally-efficient communications. Concurrently, the system must be scalable, accommodating future growth in response to augmented demand for capacity and escalating bandwidth requirements.
    \item\textbf{Interoperability} : In the context of a maritime system, it is imperative for vessels and maritime devices to receive services from other systems or networks. The integration and cooperative utilization of data within and across network boundaries should be guaranteed. Furthermore, it should ensure the timely and seamless portability of information across the full spectrum of maritime services 
    \item\textbf{Radio Spectrum Internationality} : The radio spectrum is indisputably the most critical component for any wireless communication system. This is particularly true for maritime systems due to its global coverage nature. To successfully deploy the system globally and ensure proper functionality, it is imperative that an international frequency band be made available and established with suitable standards and regulations. To achieve this objective, it is essential that international standards and regulatory bodies, in collaboration with the global maritime community, address the technical and regulatory challenges.
\end{itemize}

\subsection{IoT Security}
The maritime industry's reliability and sustainability are of paramount importance to the economic success of nations worldwide. Vessels are critical transportation systems that facilitate the global movement of goods. Ensuring safety and security within the maritime industry is contingent upon the implementation of robust cybersecurity measures. The advent of fully or semi-autonomous systems, which demand minimal human intervention, necessitates a comprehensive evaluation of the inherent security vulnerabilities and risks associated with the adopted technology. As articulated in \cite{cyber_incident_scenarios}.

It is imperative to acknowledge that critical attacks that can be perpetrated against maritime OT systems that leverage IoT communication systems can assume various forms, depending on the attack vector. Examples of such vectors include:

\begin{itemize}
    \item\textbf{Tug boat cyberattacks} : The communication systems utilized on tug boats to interface with other vessels or shore-based facilities are susceptible to cyberattacks, which can result in a loss of communication or even a complete system takeover. These cyberattacks can manifest in various forms, such as jamming, spoofing, or interception of communication signals. Jamming, for instance, can disrupt communication signals, impeding the tug boat's ability to communicate with other vessels or shore-based facilities. Spoofing involves the transmission of false signals to the tug boat's communication systems, tricking them into executing unauthorized instructions, which can result in erroneous actions or compromised safety. Finally, interception can result in the exposure of sensitive or confidential information to unauthorized third parties. 
    \item\textbf{Harbour manoeuvres incidents} :The cybersecurity risks associated with the entire apparatus of sensors, such as laser sensors, ultrasound systems, and radar, are relatively low. This is due to the fact that they are standalone devices that are not connected to any network or system. Nevertheless, concerns regarding data interception or tampering during transmission persist, particularly in scenarios involving wireless transmission. Furthermore microwave transponders, portable pilot devices, and automatic identification systems facilitate communication between vessels and shore-based monitoring units, introducing a series of cyber vulnerabilities that can be critical for harbor manoeuvres, resulting in unauthorized access, connection jamming, and data tampering.
    \item\textbf{Berthing Aid System} : Unauthorized access to the BAS by an
    employee can result in data breaches and system damage through display of incorrect information. This could occur due to an employee accessing the system without the proper authorization or credentials. Access to the  BAS should be restricted to authorized personnel only based on the principle of least privilege, since employee withoutout proper knowledge could potentially delete or corrupt data stored in the system, leading to data loss or system failure
\end{itemize}

\subsection{Considerations}

The implementation of a solution that addresses the aforementioned concerns regarding compatibility and security would necessitate a substantial allocation of resources and time, as previously indicated. Conversely, our proposed solution can be seamlessly integrated into existing infrastructures using today's standards, with a minimal time requirement for testing. The design choices that have been implemented result in a high degree of modularity, which in turn allows for extreme adaptability to legacy systems and suboptimal infrastructures.

\section{Application solutions}
In addressing the imperative to bolster cybersecurity measures within the OT landscape, alternative solutions have been proposed. These solutions prioritize enhancing network security through the utilization of user space applications. This approach bears a certain resemblance to our implementation previously outlined, albeit with certain caveats that introduce a degree of uncertainty in its reliability. 

System hardening entails the implementation of security controls that serve to reduce the attack surface and enhance the security posture of the systems. This involves the implementation of security controls such as firewalls, intrusion detection and prevention systems, access controls, and other security measures that are intended to limit the potential for successful cyberattacks. This approach, when implemented, can effectively mitigate the risk of successful cyberattacks and enhance the overall security of critical infrastructure. However, from an applicative point of view, the hardening of legacy systems poses significant obstacles due to their intrinsic nature.

This path is fraught with challenges related mainly to compatibility , management and security, such as 

\begin{itemize}
    \item\textbf{Dependecy Risk} : In the context of conventional IT systems, the repercussions are commensurate with specific human activities, and the user has the capacity to ameliorate the impact through manual interventions. Conversely, in the context of OT, enterprises must exercise caution in the management of dependencies on IT components, with the objective of averting the potential for adverse impact on physical processes in instances where human intervention is not feasible. Given the inherent limitations of mitigation in OT, the most effective approach is often to exercise control over dependencies to avert potential impacts.
    \item\textbf{Data Management} : The data produced by OT devices can be voluminous, diverse in content, time sensitive for consumption, and geographically distributed. Conversely, the majority of IT systems exhibit a certain degree of tolerance for time delays, are constrained in size and content, and are reliably connected to company networks, facilitating accessibility to IT staff for data management and support. Conversely, OT systems necessitate a determination by the company regarding the integration of the data into the enterprise data landscape or the potential for the data created by the OT system to remain self-contained and local.
    \item\textbf{Application Security} :  The integration of OT systems with IT has been shown to create additional vulnerability targets, caused by an enlargement of the attack surface to the user space specific interactions, potentially impacting not just people and data, but also physical processes.
\end{itemize}

The implementation's primary function is to operate at the kernel level, leveraging the user space as a data management platform without requiring user interaction. This approach has enabled the creation of a tool that is free from dependencies and can be programmed to process data in real-time if needed. Furthermore user interaction is not needed and  the potential for user-interaction specific threats is completely eradicated.







