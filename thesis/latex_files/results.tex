\chapter{Results}
\label{ch:results}

In this chapter, an analysis is conducted of the results obtained from the execution of multiple tests on the software under investigation. Since tests over the implementation's correctness are trivial by design the focus is on network speed. The results are then compared with the performance of OT systems traditional networking techniques. Furthermore, an assessment is made of the advantages and disadvantages of the L7 switch. 

\section{Linux baseline }
In order to ascertain the viability of our implementation as a substitute for current standards, it was necessary to establish a baseline, defined as the average speed at which UDP packets travel in a maritime network. Due to the unavailability of a real OT environment for testing our switch, all tests were conducted using the previously analyzed Network Namespace technology. Given the information flow characteristics of naval systems, as outlined in the background section, the initial tests centered on the normal unfiltered data exchange. As the data payload values were not a factor in this testing phase and the generation of a plausible amount of data was necessary, the iperf3 tool was selected. This software enabled easily the recreation of a reliable environment, in which data flows at approximately 1 Gbit/s with a default UDP packet size of 1460 KB between two components.

Initially, it was necessary to ascertain whether the implementation of system emulation utilizing network namespaces would result in the introduction of overhead, which could potentially compromise the reliability of the tests from the outset. Consequently, experiments were executed on the data exchange between emulated components, leveraging the Linux Network Stack.


\leavevmode\newline\\

\begin{tabularx}{\textwidth}{|>{\hsize=1\hsize}X|>{\hsize=1\hsize}X|>{\hsize=1\hsize}X|}
  \hline
  \multicolumn{3}{|l|}{\textbf{Iperf tool results - Linux Network Stack Unicast }} \\ \hline
    Role & Bitrate Mbit/s & Datagram size B\\ \hline
    SENDER & 1000& 1460\\ \hline
    RECEIVER  & 1000 & 1460    \\ \hline
    SENDER & 4800 & 8972\\ \hline
    RECEIVER  & 4800  & 8972 \\ \hline
\end{tabularx}

\leavevmode\newline\\

As evidenced by the iperf tool's output, the namespace abstraction did not result in any additional overhead maintaining a bitrate of 1 Gbit/s between the sender and receiver. Having established a baseline that should emulate a real-life scenario, we proceeded to test a filtered unicast information flow, leveraging our switch implementation with the same iperf parameters.

\leavevmode\newline\\

\begin{tabularx}{\textwidth}{|>{\hsize=1\hsize}X|>{\hsize=1\hsize}X|>{\hsize=1\hsize}X|}
  \hline
  \multicolumn{3}{|l|}{\textbf{Iperf tool results - Rust/AF\_XDP Unicast }} \\ \hline
    Role & Bitrate Mbit/s & Datagram size B\\ \hline
    SENDER & 1000& 1460\\ \hline
    RECEIVER  & 1000 & 1460    \\ \hline
    SENDER & 4800 & 8972\\ \hline
    RECEIVER  & 4800  & 8972 \\ \hline
\end{tabularx}


\begin{figure}[H]
	\centering
    \includegraphics[scale=0.45]{thesis/images/rust_performance_afxdp_unicast_sender.png}
	\caption{Bitrate over time - Sender AF\_XDP- Unicast flow - 1460B Dataframes}
    \label{fig:iperf_performance_AF_XDP_sender}
\end{figure}

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.45]{thesis/images/rust_performance_afxdp_unicast_receiver.png}
	\caption{Bitrate over time - Receiver Rust/AF\_XDP- Unicast flow - 1460B Dataframes}
    \label{fig:iperf_performance_AF_XDP_receiver}
\end{figure}

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.45]{thesis/images/rust_performance_afxdp_unicast_sender_5.png}
	\caption{Bitrate over time - Sender Rust/AF\_XDP- Unicast flow - 8972B Dataframes}
    \label{fig:iperf_performance_AF_XDP_sender_5}
\end{figure}

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.45]{thesis/images/rust_performance_afxdp_unicast_receiver_5.png}
	\caption{Bitrate over time - Receiver AF\_XDP- Unicast flow - 8972B Dataframes}
    \label{fig:iperf_performance_AF_XDP_receiver_5}
\end{figure}

An examination of the iperf results and the graph obtained from analyzing the network traffic within the switch revealed that our implementation did not modify the data exchange speed. This observation indicates that the Linux Network stack baseline was maintained without introducing additional overhead in the unicast scenario.
