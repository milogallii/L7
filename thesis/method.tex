\chapter{Level-7 Switch}\label{ch:method}

In this chapter, we present our Layer-7 switch using AF\_XDP technology and its application to a simulated maritime operational technology system.
In particular, we will highlight the differences between a traditional Layer-2/Layer-3 switch and our implementation, with a focus on its smart-filtered data flow.
The following sections describe in great detail the analysis steps leading to the final project architecture.

\section{From L2 to L7}
When we talk about a "layer" in switch terminology, we are referring to the Open System Interconnection (OSI) layer the switch operates on.
Today's implementations, applied to maritime OC systems, work on the the Data Link layer (L2) operating eventually on the Network Layer (L3).
The lower one being responsible for MAC-Address based forwarding of data frames.

Traditionally network device interfaces (NICs), each one with a unique MAC address, are connected to the switch via physical Ethernet ports or fiber optic ports depending on speed requirements.
When a NIC sends data to the switch its MAC address is inserted inside a very simple data structure, called the MAC address table, which contains basic routing information.
If the table contains the packet's destination address, the packet is routed to the associated port otherwise it is sent to all ports except the sender's, creating a packet "flood".

Requiring no routing algorithm, and not needing IP addresses to forward data, Layer 2 switches are very fast, and cost less than routers. However, broadcast traffic is not controlled leading to network congestion while handling high workloads. Lastly, these kind of switch cannot pass data between different VLANs precluding network segmentation.

Faced with the practical and performance limitations of lower-layer switches, there has been a move toward Layer 3 implementations, especially in industrial network topologies.
To ensure flexible application planning a host of Network Layer features are quickly became “must haves”.

Layer 3 packet routing is performed by routers that use IP addresses instead of MAC addresses, making this new paradigm ideal for local area networks. Switches that use this strategy can connect different VLANs, provide more security features, and apply Quality of Service (QoS) controls for maximum efficiency. 

Using an ARP table data structure which shows both MAC and IP addresses, switches will either forward the packet like a Layer 2 switch, or route it according to a routing protocols.

\leavevmode\newline
\begin{tabularx}{\textwidth}{|>{\hsize=0.5\hsize}X|>{\hsize=0.5\hsize}X|}
  \hline
  \multicolumn{2}{|c|}{\textbf{L2/L3 Features}} \\ \hline
  L2 & L3 \\ \hline
  Sends data “frames” to destination MAC address & Routes data “packets” based on MAC or IP address\\ \hline
  OSI Layer 2 (Data Link Layer) & OSI Layer 3 (Network Layer)\\ \hline
  Cannot connect different VLANs & Able to connect different VLANs\\ \hline
  One broadcast domain & Multiple broadcast domains \\ \hline
  Communicates with local network & Can connect to outside (multiple) networks\\ \hline
\end{tabularx}
\leavevmode\newline \\

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.045]{thesis/images/L2_L3_switch_architecture.png}
	\caption{Visualization of architecture that leverages L2 and L3 switches}
    \label{fig:L2_L3_architecture}
\end{figure}

The two types of switches analyzed so far are capable of routing network traffic using different strategies, some more optimized than others. However, their functionality can be described as a "passive" way of managing data exchange, dictated by the switches' own implementation. There is no active process of handling  network traffic, such as simply controlling that two components are allowed to "talk" to each other because the task is simply delegated to components' specific applications.

The solution to this problem resides in the Application Layer (L7) where expressive power over packets is almost limitless while being capable of low level routing.
As said before this is an expression of the Software Defined Networking paradigm, where packet routing tasks are shifted from hardware to programmable software. 

The baseline is the creation of a piece of software, written in any programming language, that creates an eBPF program with a XDP hook that attaches to the all the NICs of a designed architecture.
Once the program is attached to the network interfaces an AF\_XDP socket is created for each one and all the traffic sent and received by them is redirected to a user-space application.
The application mentioned above is completely responsible for any action performed on the packets, being that dropping, filtering or simply redirecting them to the original destination.
\\

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.2]{thesis/images/L7_switch_architecture.png}
	\caption{Visualization of architecture that leverages a L7 switch}
    \label{fig:L7_architecture}
\end{figure}

\section{L7 Networking}

Once packets are redirected to user space by AF\_XDP sockets, the data flow becomes extremely flexible.
Hardware components such as Layer-2 and Layer-3 switches can be abstracted into data structures, as well as the network traffic itself. Following this principle, it's trivial to assume that fully personalized data-flows can be implemented according to predetermined sets of rules, which we'll call \textbf{policies}.

Since the ultimate goal is also to be completely hardware agnostic, it is necessary to preserve basic routing, previously physically handled, for packets that are not bound to network policies. Thereby two main flows can be identified, basic and filtered.

\subsection{Basic Data Flow}
In this scenario the goal is to reproduce the behaviour of a Layer-2 switch in user-space.
Focusing on that a data structure that will take the physical hardware's place will be created, such as hash-map, as well as one additional other to store the traffic received by our application, that will be a vector.
A struct called pollfd will be associated as well to the AF\_XDP socket bound to the components' network interfaces. This will allow us to know which components have data to read and optimize iteration over components.

Once these data structures are set the algorithm can be break down as follows:

\begin{enumerate}
    \item The pollfd structure bound to a component's socket is checked in order to know if there's new data available
    \item The RX Ring Buffer of the socket is read and a network packet will be available for processing
    \item Since we are not interested in handling data more than necessary in this implementation we just check if the packet's sender is already in the "hash-map-switch" and if not we add it creating an association between the source MAC address and the system's component
    \item If the destination address is known we insert the packet, as long as the associated component, into the data structure that represents the system's traffic, otherwise we should apply a "flood" technique, which broadcasts the packets to all components to hit the correct one. To do so we add to the traffic multiple copies of the packet, one for each component
    \item The packet is then added to the Fill Ring Buffer of the socket's UMEM, indicating complete receival, and new memory frames are added to the Fill Ring Buffer.
    \item Iterating over the traffic vector packets are then added to the socket TX Ring Buffer and transmitted to the destination MAC address if known, broadcasted to all addresses if not
    \item Once transmission is over packets are added to the Completion Ring Buffer of the socket's UMEM, indicating complete transmission
\end{enumerate}

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.3]{thesis/images/af_xdp_socket_visualisation.png}
	\caption{Visualization of an AF\_XDP socket}
    \label{fig:L7_architecture}
\end{figure}

\subsection{Filtered Data Flow}
Once the basic flow is implemented, modifying it to provide filtering capabilities becomes trivial.
Once the packet is in the RX ring buffer and fully received, almost any task can be performed before sending or dropping it, such as applying rule sets.

\subsubsection{Policy Based Filtering}
A policy-based network is easier to automate and therefore more responsive to changing needs. Many common tasks, such as adding devices and inserting new services can be easily accomplished.

Well-defined policies can benefit a network : 
\begin{itemize}
    \item Aligning the network with business needs
    \item Providing consistent services across the entire infrastructure
    \item Bringing agility through greater automation
    \item Making performance dependable and verifiable
\end{itemize}

An even greater benefit to systems is the security provided by policy.
By granularly defining policies that give devices the least amount of access to resources, the protection of sensitive data is enhanced. Violations can be quickly detected and mitigated, while zero-trust security measures reduce risk, contain threats, prevent malicious lateral movement, and help verify regulatory compliance.

In particular, our implementation is aimed at maritime OC systems whose internal communication is based on the NMEA-0183 and NMEA-2000 protocols, where information is sent through unencrypted UDP data frames containing ASCII payloads, with no restrictions on the flow direction of the communication.

To formalize and secure packet processing, a set of rules must be defined to guide decisions and actions. This task can be accomplished by creating configuration files that guarantee the achievement of specific filtering goals.

Considering that the policy applied to packets should provide directional restriction rules that determine which NMEA messages can be sent and received by each component.
Once the conformity of UDP data frames with the policy is verified, the fate of the packets branches into two possible outcomes, which are 

\begin{itemize}
    \item\textbf{Packet Drop} : The packet is not added to the system's traffic data structure and is therefore not considered in the data transfer phase.
    \item\textbf{Packet Multicast Transmission} : Following the design of the NMEA protocol, the packet is sent to any component of the system that is allowed to receive it according to the policy rules. On this principle, the packet is multiplied and its destination addresses and checksums are processed to ensure its structure conforms to the recipient specifications.
\end{itemize}
