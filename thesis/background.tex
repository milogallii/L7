\chapter{Background}
\label{ch:background}

In this chapter, we delineate the principles of contemporary naval communications, emphasizing the characteristics and deficiencies of prevailing standards (NMEA).
The subsequent discussion will address the necessity for "software-defined networking" and the innovative technologies underpinning network administration, EBPF and AFXDP.


\section{Naval Networks}\label{sec:naval_networking_and_nmea}

A naval network, otherwise referred to as an \textbf{integrated shipboard communication system} is a sophisticated and meticulously organized system designed to facilitate communication, data exchange, and operational coordination whithin subsystems and devices on the vessel. 
Given the numerous elements that contribute to the ship's apparatus, such as navigation systems, sensors and monitoring systems our focus will be directed exclusively towards the communication limb that directly interests our final goal.

\subsection{Communication systems}
Communication systems facilitate seamless communication of the vessel both internally and externally ensuring the continuous exchange of data.
The field of external communication can be subdivided into three primary categories :

\begin{itemize}
    \item\textbf{Command and Control (C2)},for long-range capabilities such as communication with shore-based command centers, other ships and aircrafts
    \item\textbf{Tactical Coordination}, for short-to-medium range communication which are critical for coordination and emergency communications
    \item\textbf{Emergency Communication},for real time data exchange among various components allowing coordinated operations among ships, aircrafts and ground entities
\end{itemize}

External side communication's capstone can be identified in the usage of the Satellite Communication (SATCOM) protocol that enables beyond-line-of-sight (BLOS) data exchange providing global, high-bandwidth, and secure connectivity. However, it is part of a broader ecosystem that includes radio communication, data links, and underwater communication systems.\\
Internal communication, on the other hand, although it comprises crew coordination systems the main body consists of devices that provide a unified picture among navigation, propulsion and management environments. Vessels are designed to establish an informational circulatory system within them that consists of a physical apparatus composed of various components such as switches, routers, gateways, and servers. The flow of information within it falls into five distinct categories: 

\begin{itemize}
    \item\textbf{Navigation and Situational Awareness}, data transmitted over the network and integrated into the Management System, providing a real-time operational picture
    \item\textbf{Threat Detection and Response}, data signaling potential threats coming from the sensoring systems
    \item\textbf{Engine Monitoring and Control}, data allowing the crew to monitor and optimize the ship's propulsion and power systems
    \item\textbf{Crew Communication}, intercom system's data to coordinate crew actions
    \item\textbf{Cybersecurity Monitoring}, cybersecurity systems data that ensure integrity and safety of the ship
\end{itemize}

\subsection{NMEA}

Given the wide range of the aforementioned messages in the early years of 1980 the \textbf{National Marine Electronics Association (NMEA)} introduced the first kind of protocol to standardize communication for marine electronics.
Since its inception, the protocol has evolved significantly to accommodate advancements in technology and the expanding needs of different industries.

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.35]{thesis/images/nmea_timeline.png}
	\caption{NMEA Protocols' Creation timeline}
    \label{fig:nmea_timeline}
\end{figure}

\subsubsection*{NMEA 0183}
The protocol underwent a series of modifications, beginning with the 0180 and 0182 versions. However, these initial implementations were swiftly discarded in favor of the subsequent iteration, the 0183. This new version's adoption as the primary standard for serial communications can be attributed to its simplicity and comprehensive functionality, providing the vessel's components a complete overview of other one's status through simple text.

This standard utilizes a rudimentary ASCII serial communications protocol, which delineates a method where data are transmitted in a \textbf{sentence} from a single \textbf{talker} to multiple \textbf{listeners} concurrently. The protocol enables a talker to engage in a unidirectional conversation with an almost limitless number of listeners by employing intermediate expanders, and it facilitates communication between multiple sensors and a singular port through the use of multiplexers.  

Although the protocol stipulates the use of RS-422 for electrical transport, a de facto standard has emerged in which sentences are \textbf{encapsulated in UDP datagrams} and \textbf{transmitted over IP networks}.

\paragraph{Message structure}
\leavevmode\newline\\
    All messages must be composed of printable ASCII characters between \textit{0x20} (space) to \textit{0x7e} (tilde) including a set of special characters that define the syntax
    
\begin{tabularx}{\textwidth}{|>{\hsize=0.5\hsize}X|>{\hsize=0.5\hsize}X|>{\hsize=1\hsize}X|}
  \hline
  \multicolumn{3}{|c|}{\textbf{Syntax characters}} \\ \hline
  ASCII & HEX & USE \\ \hline
  \textless CR\textgreater  &  0x0d   & Carriage return        \\ \hline
  \textless LF\textgreater   & 0x0a    & Line feed, end delimiter       \\ \hline
  !    & 0x21   &   Start of encapsulation sentence delimiter   \\ \hline
  \textdollar     & 0x24   & Start delimiter      \\ \hline
  *    & 0x2a    & Checksum delimiter     \\ \hline
  ,    & 0x2c   & Field delimiter       \\ \hline
  \textbackslash     & 0x5c   & TAG block delimiter        \\ \hline
  \textasciicircum    & 0x5e     & Code delimiter for HEX representation of ISO/IEC 8859-1 (ASCII) characters     \\ \hline
  \textasciitilde     & 0x7e    & Reserved       \\ \hline
\end{tabularx}

\leavevmode\newline\\
Moreover, adherence to established syntax rules is imperative for the purpose of ensuring compliance with the protocol, in particular :

\begin{itemize}
    \item Messages have a maximum length of 82 characters, including the \textdollar \ or ! starting character and the ending \textless LF\textgreater
    \item The start character for each message can be either a \textdollar (For conventional field delimited messages) or ! (for messages that have special encapsulation in them)
    \item The next five characters identify the \textbf{Talker Id} (two characters) and the \textbf{Sentence Type} (three characters)
    \item All data fields that follow are comma-delimited
    \item Where data is unavailable, the corresponding field remains blank (it contains no character before the next delimiter
    \item The first character that immediately follows the last data field character is an asterisk, but it is only included if a checksum is supplied
    \item The asterisk is immediately followed by a checksum represented as a two-digit hexadecimal number. The checksum is the bitwise exclusive OR of ASCII codes of all characters between the \textdollar \ and *, not inclusive.
    \item \textless CR\textgreater \textless LF\textgreater \ ends the message
\end{itemize}

The following is a list of the most common messages that appeared in the early days of this technology, constituting the first kind of standardized communication:
\leavevmode\newline\

\begin{tabularx}{\textwidth}{|>{\hsize=0.75\hsize}X|>{\hsize=1.25\hsize}X|}
  \hline
  \multicolumn{2}{|c|}{\textbf{NMEA 0183 Common Sentences}} \\ \hline
  Sentence Type & Description \\ \hline
   \textdollar Talker ID+GGA  & Global Positioning System Fixed Data         \\ \hline
   \textdollar Talker ID+GLL    & Geographic Position—Latitude and Longitude       \\ \hline
  \textdollar Talker ID+GSA   &   GNSS DOP and active satellites    \\ \hline
   \textdollar Talker ID+GSV  & GNSS satellites in view      \\ \hline
   \textdollar Talker ID+RMC   & Recommended minimum specific GPS data     \\ \hline
   \textdollar Talker ID+VTG   & Course over ground and ground speed      \\ \hline
\end{tabularx}

\paragraph{Protocol security}

\leavevmode\newline\\

The protocol's conception predates the conceptualization of vehicle hacking, thus lacking any inherent security measures to protect network information flows from potential attacks.
To date, the research community has conducted only a limited number of studies on the security of network marine protocols. Moreover, there is a paucity of research on risk analysis for this type of communication.

As is the case with other networking protocols, marine protocols are susceptible to malicious attacks and unintentional human errors. It is incumbent upon manufacturers to consider the extended Confidentiality, Integrity, and Availability (CIA) model, which encompasses Authentication, Authorization, and Non-repudiation from the creation to implementation and maintenance of network device firmware. 

As of the present date, only naive solutions have been implemented in order to address these primary security concerns :

\begin{itemize}

    \item\textbf{Confidentiality} : Due to the limitation of bandwidth in many marine network protocols, encryption mechanisms are not implemented. Consequently, the predominant approach to ensure confidentiality for these systems is primarily through access control.
    
    \item\textbf{Integrity} : Vessels generate substantial surges in network traffic, which often surpasses the bandwidth capacity of the ship. This phenomenon can result in service disruptions and latency as various services compete for bandwidth. One proposed solution to this challenge is the implementation of a master device in conjunction with multiple remote devices. In instances where a high-priority bandwidth requirement is identified, a remote device can be temporarily allocated to an auxiliary channel, thereby facilitating the management of network traffic.
    
    \item\textbf{Availability} : The majority of maritime communication protocols are designed to support slow transfer speeds. Therefore, the protection for availability is contingent upon the hardware specification and configuration, allowing for data transfer at the maximum data rate of the protocol. In the context of critical systems that necessitate uninterrupted accessibility, the implementation of hardware redundancy and backup mechanisms becomes imperative.

    \item\textbf{Authentication} : A select number of shipping protocols incorporate optional authentication mechanisms that are not specialized for the protocols themselves. These include the Global Navigation Satellite System (GNSS) and systems adopted from vehicular networks. Consequently, under theory, these protocols possess the potential to be adapted to support authentication for marine networks; however, this functionality is not currently available.

    \item\textbf{Authorization} : A considerable number of protocols incorporate a form of an ID tag to identify the communication nodes, along with their privileges, as well as access rights, inside a network. However, in the absence of adequate inspection mechanisms, a malicious device can potentially generate its own ID with a high level of authorization, thereby circumventing access controls and gaining unauthorized access to sensitive information. 

    \item\textbf{Non-Repudiation} : This concern has witnessed a marked rise in prominence, particularly in the context of forensics and legal challenges. Non-repudiation is poised to assume greater significance; however, at present, no non-repudiation technique has been implemented in any substantial manner.
    
\end{itemize}

As the protocol undergoes continuous development and enhancement, \textbf{theoretical analyses} were conducted to evaluate the current state of data exchange security in response to prevalent attacks. The objective of this endeavor was to identify vulnerabilities that could be exploited by an attacker to compromise the protocol.
The subsequent list of attacks is not intended to be exhaustive; rather, it is designed to illustrate the most critical violations that can be perpetrated in networks that utilize the protocol:

\begin{itemize}
    \item\textbf{Denial of Service (DoS)}: targets the availability of data
    \item\textbf{Spoofing}: targets the integrity of data.
    \item\textbf{Packet sniffing}: targets the confidentiality of data.
    \item\textbf{Replay/Man-in-the-Middle (MITM)}: targets both confidentiality and integrity of data.
\end{itemize}

It is important to note that the NMEA 0183 protocol does not incorporate any mechanisms for authentication, encryption, or validation. The absence of security measures inherent to the protocol renders it vulnerable to any of the aforementioned attack if utilized effectively by an adversary

\leavevmode\newline\\

\begin{tabularx}{\textwidth}{|>{\hsize=0.75\hsize}X|>{\hsize=1.25\hsize}X|}
  \hline
  \multicolumn{2}{|c|}{\textbf{Attacks against the NMEA 0183 protocol}} \\ \hline
  Attack & Methodology \\ \hline
    Denial of Service & NMEA 0183 supports a baud rate of 4800 (9600 bits/s). This makes a DoS attack potentially effective against any devices using this protocol depending on the means through which data is transferred to an application \\ \hline
    Spoofing/Packet Sniffing   & Spoofing and sniffing has been shown to be trivial against the standard using simple traffic simulation software     \\ \hline
    Replay/Man-in-the-Middle &  Leveraging software that that intercepts and manipulates data exchanged modifiying critical missions' informations such as coordinates coming from sensor devices  \\ \hline
\end{tabularx}

\subsubsection{NMEA 2000}
The fourth iteration of the protocol resulted in a more advanced implementation, characterized by more sophisticated structural choices that increased performance. Regrettably, the security standards remained unaltered.

\paragraph{Key changes}
\leavevmode\newline

The backbone of this new version's enhancements can be identified in the standard communication being based on the \textbf{Controller Area Network (CAN)} Bus protocol.
CAN protocol utilizes a priority-driven and message-based architecture capable of operating at either 512 Kbps or 128 Kbps.

Each device that transmits CAN Bus signals is considered a node with its own priority level and during transmission, nodes continuously check the signal on the bus comparing it
with the signal they are transmitting. If a mismatch occurs, an error is raised and the internal error counter is incremented to prevent having broken nodes continuously flooding the network. The right of a node to raise errors can be disabled depending on the value of these counter granting that communication over CAN Bus is reliable.

The advent of this novel information flow structure has enabled the transmission of data messages at elevated speeds as data frames characterized by the incorporation of robust error checking mechanisms, confirmed frame delivery, and guaranteed latency times.
Additionally, the transmission of information as binary messages, as opposed to ASCII text, facilitates more efficient and secure data exchange.
This was done mantaining a relatively simple message structure organized as follows 
\begin{itemize}
    \item\textbf{GN (Parameter Group Number)} :Defines the type of data being transmitted
    \item\textbf{SPN (Suspect Parameter Number)}: Identifies specific data fields within a PGN
    \item\textbf{Data Length}: Specifies the length of the data in bytes
\end{itemize}

This implementation choice was made also in light of the following key advantages concerning the physical characteristics of this type of communication: 

\begin{itemize}
    \item\textbf{Simple and Cheap}: Components communicate via a single CAN system instead of via direct complex analog signal lines reducing errors, weight, wiring, and costs.
    \item\textbf{Fully centralized architecture} : Only one point of entry is set to communicate with all network components enabling central diagnostics, data logging, and configuration.
    \item\textbf{Extremely Robus and Efficient} : the system is robust towards electric disturbances and electromagnetic interference - ideal for safety-critical applications
    AN frames are prioritized by ID numbers. The top priority data gets immediate bus access, without causing interruption of other frames.
\end{itemize}

\leavevmode\newline\\

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.15]{thesis/images/nmea2000_can.png}
	\caption{NMEA2000 Protocol with CAN Bus communication}
    \label{fig:nmea2000can}
\end{figure}

\paragraph{Protocol Security}
\leavevmode\newline

The NMEA 2000 standard did not incorporate any inherent security features related to confidentiality, authentication, authorization, or non-repudiation, which were not present in the previous versions.
The implementation of controls for potential attack vectors is delegated to nodes, which utilize their own \textbf{application-specific} protocols operating on top of the marine network.
Therefore, an analysis of the protocol itself, absent any top-level software add-on, reveals that the vulnerabilities identified in previous iterations have reemerged, albeit with modified attack methodologies.

\leavevmode\newline\\

\begin{tabularx}{\textwidth}{|>{\hsize=0.75\hsize}X|>{\hsize=1.25\hsize}X|}
  \hline
  \multicolumn{2}{|c|}{\textbf{Attacks against the NMEA 2000 protocol}} \\ \hline
  Attack & Methodology \\ \hline
    Denial of Service & Leveraging the protocol's low-bandwidth design malicious devices or poorly configured ones could produce a large amount of traffic without raising errors on the main bus message channel, preventing other devices from communicating
studies \\ \hline
    Spoofing & Exploiting situations where the Parameter Group Number (PGN) used to identify the sending node is copied and used by a malicious device. This imposes more problems since PGN is also used to indicate the priority of messages. \\ \hline
    Packet Sniffing & Since NMEA 2000 operates on a single broadcast domain where all nodes on the message channel receive all messages. Since the responsibility to discern which messages to discard as unneeded is delegated to nodes passive sniffing of messages is a trivial task, assuming physical access is possible.   \\ \hline
    Replay/Man-in-the-Middle & Considering the protocol's broadcast principle, an inline device could be placed between the target node and the rest of the channel (bus). This malicious inline device would be able to pass along messages from either the target node or the rest of the channel in either direction. \\ \hline
\end{tabularx}

\leavevmode\newline

\subsubsection{Considerations over the standard}
NMEA 0183 and NMEA 2000 have achieved widespread acceptance among manufacturers and maritime agencies worldwide, receiving frequent updates and support.\\ Attempting to modify these standards would necessitate years of adjustments, aiming to align with current hardware infrastructures that are utilized on a daily basis by a wide range of essential services.\\ However, as previously emphasized, the absence of security measures necessitates the urgent development of a compatible and transparent solution for the naval ecosystem.

\section{Software Defined Networking - SDN}
The urgent pursuit of alternatives that would seamlessly integrate with current naval systems' architecture without introducing new communication standards has prompted the consideration of Software Defined Networking (SDN).

This technology can be defined as an approach to networking that uses software-based controllers or application programming interfaces (APIs) to communicate with underlying hardware infrastructure and direct traffic on a network.\\
Contrary to state-of-the-art solutions which utilize dedicated hardware devices (e.g., routers and switches), SDN possesses the capability to create and control a virtual network or to manage a traditional hardware configuration through the use of software.

This new way of intending data flow differs also from network virtualization where either a multitude of virtual networks is segmented within a single physical one in order to separate components or different physical networks are merged to create a single virtual one.
In contrast, software-defined networking enables a new way of controlling the routing of data packets through a centralized server while leaving physical and virtual configurations unaltered.

\subsection{Operational Process}
The technology's paradigm relies on software rather than hardware for its operations. This inherent characteristic bestows upon it a superior degree of flexibility when compared with traditional networking methodologies.

With SDN administrators exercise comprehensive control over the network via a single pane of glass, modifying configuration settings, allocating resources, and augmenting network capacity.

Since software is decoupled from the hardware the three fundamental components of SDN can be situated in disparate physical locations:

\begin{itemize}
    \item\textbf{Applications} which communicate resource requests or information about the network as a whole
    \item\textbf{Controllers} which use the information from applications to decide how to route data packets
    \item\textbf{Networking devices}, which receive information from the controller about where to move the data
\end{itemize}

Eventually, additional software components may be embedded in either the software or the hardware to assume the responsibilities of physical switches and consolidate their functions into a single, intelligent switch.
The switch is responsible for verifying the integrity of data packets and their virtual machine destinations, thereby facilitating the efficient transmission of packets.

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.35]{thesis/images/sdn.png}
	\caption{Example of Software Defined Networking structure}
    \label{fig:nmea2000can}
\end{figure}

\subsection{SDN Benefits}
Software defined networking facilitates the seamless and regulated migration of data among distributed locations, a functionality that is paramount for systems comprising numerous components, each overseeing distinct workloads and transmitting signals across disparate domains.
The subsequent aspects can be regarded as the pivotal characteristics that contribute to the technology's value and reliability:

\begin{itemize}
    \item\textbf{Increased control with greater speed and flexibility} : Instead of manually programming multiple vendor-specific hardware devices, developers can control the flow of traffic over a network simply by programming an open standard software-based controller. Networking administrators also have more flexibility in choosing networking equipment, since they can \textbf{choose a single protocol} to communicate with any number of hardware devices through a central controller.

    \item\textbf{Customizable network infrastructure} : Administrators can configure network services and allocate virtual resources to change the network infrastructure in real time \textbf{through one centralized location}. This allows network administrators to optimize the flow of data through the network and prioritize applications that require more availability.

    \item{Robust security}: A software-defined network delivers visibility into the entire network, providing a more holistic view of security threats where operators can \textbf{create separate zones for devices that require different levels of security}, or immediately quarantine compromised devices so that they cannot infect the rest of the network.
\end{itemize}

\subsection{Application to Legacy Systems}

The concept of centralized software regulating the flow of data in switches and routers is applicable to all software-defined networking (SDN). However, there are distinct SDN models, each with its own unique application environments and customized to address specific requirements.

The solution that best fits the role of integrating modern data flow strategies while being limited by hardware and software standards is Hybrid SDN.

This model combines software-defined networking with traditional networking protocols in a single environment, thereby supporting diverse functions on a network. Standard networking protocols continue to direct some traffic, while SDN takes on responsibility for other traffic, \textbf{such as maritime message protocols}. This allows network administrators to introduce SDN in stages to a legacy environment.

This approach engenders a remarkably adaptable environment, wherein technology that is no longer supported interacts with cutting-edge innovations that address the deficiencies of outdated infrastructures.
Considering that and with SDN being merely a structural paradigm the performance limitations that could be experienced are a result of the hardware and software solutions adopted to implement such systems.

As previously mentioned anyway, the objective of this initiative is not to incorporate any additional hardware; so rather, the emphasis will be on selecting the most optimal software solution available to serve as the foundation for the final SDN architecture's implementation. The solution under consideration is the AFXDP Socket technology that enables fast and efficient data processing bypassing the traditional data flow through the Linux Network Stack.

\section{Next geration networking}

The Linux Kernel Network Stack is in charge of all network communications, processes incoming and outgoing network packets, implements various network protocols and provides application interfaces for network interaction. 
It can be thought as a layered architecture which follows the Open Systems Interconnection (OSI) model processing data from the physical network interface up to the application layer.

\subsection{Data Flow Path}

Several networking concepts together build the layered architecture mentioned earlier, where data is transformed from raw packets into structured information, and key terminology must be known in order to grasp the inner complexity of the various steps, such as:

\begin{itemize}
    \item\textbf{Ring Buffers} : Data structure particularly efficient to process data streams, continuously handling new data that overwrites the old one. Network Interface drivers uses them to allocate Receive (RX) and Transmission (TX) queues in the device memory.
    \item\textbf{Socket Buffers} : Data structure used to represent network packets used as the fundamental building block for data handling at kernel level, containing metadata and data in a layered format enabling partial editing as information gets higher in the abstraction layers.
    \item\textbf{Kernel Interrupts} :  They are signals used to stop the CPU from what it is doing and work on the interrupter’s part instead. They are divided into two kinds, top-half and bottom-half, differentiated by computational cost and calling reasons.
\end{itemize}

A brief but complete analysis of the entire process can be made once these concepts are internalized:

\begin{enumerate}
    \item At Kernel boot up, the CPU allocates packet buffers (RX and TX buffers), and builds file descriptors
    \item CPU informs the Network Interface(NIC) that new descriptors has been created to be used
    \item Direct Access Memory (DMA) fetches descriptors
    \item Packet arrives at the NIC
    \item DMA writes the packet to the RX Ring buffer
    \item NIC informs the driver which informs the CPU that new traffic is ready to be processed using Hardware Interrupt ( top-half )
    \item After the first Hardware interrupt, the Interrupt handler masks it, and instead the driver adopts the use of Software Interrupt ( bottom-half ) which is computationally cheaper for the CPU
    \item The Software Interrupt invokes the New-API subsystem, which calls the NIC Driver’s Polling function
    \item CPU process the incoming packets
    \item Some time after the Software Interrupt budget runs out and the CPU moves on to the next task
\end{enumerate}

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.35]{thesis/images/Linux_Network_stack.png}
	\caption{Data flow visualization in the Linux Network Stack}
    \label{fig:linux_ks}
\end{figure}

\subsection{Drawbacks}
While the architecture of the Linux network stack appears to be highly capable, numerous flaws become apparent in performance-critical environments, where understanding its limitations becomes necessary to design efficient and scalable networks. Key considerations include :

\begin{itemize}
    \item\textbf{Performance Overhead} : Frequent transitions and multiple packet copies between kernel and user space introduce overhead which results in low-throughput workloads. The use of buffering and queuing at multiple levels worsen general performance and traditional interrupt-driven packet processing leads trivially to high latency as New-API or polling mitigations are not enough to grant acceptable results.
    \item\textbf{Configuration} : The stack's high flexibility requires deep expertise to be leveraged in order to optimize performance for high workloads and tune each layer reducing bottlenecks
    \item\textbf{Scalability} : Steps of the network stack, such as the kernel's TCP/IP processing, can become bottlenecks in multi-core systems being Single-threaded by design, limiting scalability.
   \item\textbf{Lack of Real-Time Guarantees} : Since the stack was not designed for real-time systems it cannot provide strict latency guarantees leading to non-deterministic behaviors that make it less suitable for applications like \textbf{industrial control systems}.
   \item\textbf{Limited Hardware Offload Support} : While modern NICs support offloading features, legacy systems may not have the same capabilities, resulting in limited performance. In addition, different hardware and drivers may implement offload features differently, resulting in an overall inconsistent experience.
   \item\textbf{Security Concerns} : The Linux kernel is home to the Network Stack, that allows any vulnerabilities to compromise the entire system leveraging also the large attack surface
   \item\textbf{Virtualization Overhead} : In virtualized environments, the network stack can introduce additional overhead, reducing performance compared to bare-metal systems.
    \item\textbf{Debugging and Troubleshooting} : Diagnosing network issues can be difficult due to the complexity of the stack and the interactions between different components. In addition, network stack monitoring and debugging tools may not provide sufficient visibility into all layers.
\end{itemize}

\subsection{eBPF}

One of the most critical aspects of this complex structure is the difficulty of extending or fixing the kernel's functionalities. The traditional way to achieve this is to implement kernel modules, which are pieces of code that can be loaded and unloaded as needed. While using them it is possible to modify almost any feature, modules' development can be quite challenging adding complexity and risk compared to user-space software development.

In a scenario where kernel module development seemed to be the only way forward, a complete revolution took place in 2011 when the first in-kernel just-in-time (JIT) compiler for the Berkley Packet Filter (BPF) was merged.

This event led to the creation of many extensions.
A simple network packet filtering mechanism like BPF was transformed, conjugating its functionalities in the first non-networking tasks, first of all a way to filter system calls with a tool called seccomp-bpf.
The big breakthrough came in March 2014, when the first extended Berkley Packet Filter (eBPF) interpreter appeared, capable of transforming classic BPF instructions into more powerful 64-bit ones.

From then on, it became clear that eBPF would become a viable alternative to kernel module development due to its ease of use and very little basic knowledge of the Linux kernel required to develop programs.
eBPF allows running sandboxed program inside hooks points located at several places of the kernel architecture while safety is provided through an in-kernel verifier which performs static code analysis rejecting programs which crash, hang or otherwise interfere with the kernel negatively.

Doing so developers are able to add additional capabilities to the operating system at runtime as safety and execution efficiency are granted. This has led to a wave of eBPF-based projects covering a wide array of use cases, including next-generation networking, such as Express Data Path (XDP).

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.12]{thesis/images/ebpf_structure.png}
	\caption{EBPF Structure visualization}
    \label{fig:ebpf}
\end{figure}

\subsection{XDP and AF\_XDP}
As mentioned earlier, critical flaws can be highlighted whenever the Linux network stack has to deal with large workloads in environments where high throughput and low latency are key factors.
One of the solutions proposed to solve this problem was Express Data Path (XDP), a hook point located in the kernel architecture at the earliest stages of the communication data flow, inside the network device driver.

XDP grants high performance data receive and transmission letting the user bypass almost the whole networking stack let the supplied eBPF program decide the fate of packets.
Located right after the interrupt processing and before any memory allocation this technology skips the heaviest steps of networking enabling commodity hardware to elaborate 26 million packets per core per second.

The program is allowed to do anything with the packet and once finished an action code determines the packets fate.

\leavevmode\newline
\begin{tabularx}{\textwidth}{|>{\hsize=0.5\hsize}X|>{\hsize=0.5\hsize}X|}
  \hline
  \multicolumn{2}{|c|}{\textbf{XDP Action Codes}} \\ \hline
  Action Code & Description \\ \hline
  XDP\_PASS & Let the packet continue through the network stack\\ \hline
  XDP\_DROP & Silently drop the packet\\ \hline
  XDP\_ABORTED & Drop the packet with trace point exception\\ \hline
  XDP\_TX & Bounce the packet back on the same NIC it arrived on\\ \hline
  XDP\_REDIRECT & Redirect the packet on another NIC or user space socket\\ \hline
\end{tabularx}
\leavevmode\newline \\

The scope of the XDP program is limited by the kernel space environment, so a new address family has been introduced for even greater expressiveness without introducing packet identification ambiguity, AF\_XDP. 
This innovation is nothing more than a raw socket optimized for high performance packet processing using zero-copy techniques between the kernel and user space.
Leveraging this new communication paradigm, a direct channel is created from the NIC to a user application, bypassing the Linux network stack entirely and eliminating all of its associated problems.

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.3]{thesis/images/xdp_afxdp.png}
	\caption{XDP and AFXDP visualization}
    \label{fig:xdp_afxdp}
\end{figure}

\subsubsection{AF\_XDP Structure}
Very few components contribute to the creation of this ingenious technology.
A memory area, called a UMEM, is shared by both the application and the driver and it is divided into equally sized frames which can be owned by only one of the above at a time.
The UMEM relies on two memory rings, Fill (FILL) and Completion (COMP), which are single consumer / single producer, meaning that only one entity can read / write at a time.
They are used to transfer ownership of the UMEM frames between user space and kernel space.

The socket itself has two more rings, RX and TX, used for the actual exchange of the packets. The rings do not contain the actual packets but the addresses of the frames in the UMEM, as well as the length of the data for the last two rings.

\begin{figure}[H]
	\centering
    \includegraphics[scale=0.3]{thesis/images/af_xdp_socket_structure.png}
	\caption{AF\_XDP Socket Structure Visualization}
    \label{fig:afxdp_socket_structure}
\end{figure}

\subsection{AF\_XDP Optimizations}

As the Linux Networking Stack is bypassed, most of the processing is done either in user-space by the application or in the driver of the NIC. Therefore, in a simple application, most of the possible performance improvement will be obtained by modifying NIC hardware and driver settings as well as the AF\_XDP socket parameters.

\subsubsection{Hardware and Driver Settings}
Many of the optimizations brought to the networking hardware and drivers are set with the goal to achieve higher rates, in terms of bits per second (bps) or packets per second (pps). While optimizing for throughput, it's trivial to assume that some components may induce higher latency especially at lower packet rates.
A few tweaks have been discovered to lead to better performances:

\begin{itemize}
    \item\textbf{Interrupt delaying} :  Considering the fact that an interrupt signal is sent for each received packet, the traditional paradigm has to be changed when considering high packet rates. Two solutions have been considered: interrupt coalescing by New-API or by the NIC itself. The first hypothesis assumes that instead of sending an interrupt for each packet, the New-API triggers an interrupt to put the driver in poll mode. In this mode, the driver can be polled later by the kernel to process packets received since the last interrupt, saving CPU time. When operating on the NIC instead, coalescing delays trigger an interrupt when a packet is received within a certain time or frames, reducing interrupt overhead. Both mechanisms involve waiting before processing a packet, which may have negligible overhead at high packet rates, but can be significant at lower rates.
    \item\textbf{Energy Saving Mechanisms}: CPUs' integrated energy saving mechanisms, notably C-States, allow a CPU to enter a lower power state and disable some parts of itself when idle. This can lead to higher latency and jitter as the CPU may be in a energy saving mode when receiving a packet, especially at lower rates. Disabling these embedded strategies lead to better performances trivially.
\end{itemize}

\subsubsection{Socket Options}
The socket itself and the associated UMEM are also configurable. For the UMEM and the rings, the number of frames as well as their size can be configured. However, more options are available for the socket:

\begin{itemize}
    \item\textbf{Zero Copy} : By default, sending data from user space requires at least one copy of the packet between an application-owned region of memory and a kernel-owned one in order to properly format the data before sending it to the network. However support, for sending and receiving packets without copying intermediate buffers to the NIC, can be added. Also, zero-copy in AF\_XDP works on both the receiving and sending side, saving latency in both directions.
    \item\textbf{XDP\_USE\_NEED\_WAKEUP} : By setting the XDP\_USE\_NEED\_WAKEUP option, the application enables the need\_wakeup flag on the TX and FILL ring. When it is false, enables the application to write and read from the rings directly without sending a syscall to the driver beforehand which highly decreases latency. When the flag is true, the application runs in the usual mode.
    \item\textbf{Busy Polling} : In order to signal applications that packets are available, the underlying network driver will send top-half interrupts/IRQs. This downgrades overall performance if it runs on the same core as the one sending the interrupts due to context switches. Applications that leverage busy polling has to wake up the driver so it can start processing packets both on the rx and tx sides. This enables all processing to be performed on one core and therefore prevent inefficient core-to-core cache transfers. 
\end{itemize}
